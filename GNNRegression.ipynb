{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Geometric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "# load and scale the dataset\n",
    "df = pd.read_csv('SensorData.csv').dropna()\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "\n",
    "\n",
    "nodes_order = [\n",
    "    'Sensor1', 'Sensor2', 'Sensor3', 'Sensor4', \n",
    "    'Sensor5', 'Sensor6', 'Sensor7', 'Sensor8'\n",
    "]\n",
    "\n",
    "# define the graph connectivity for the data\n",
    "edges_directed = torch.tensor([\n",
    "    [0, 1, 2, 2, 3, 3, 6, 2],  # source nodes\n",
    "    [1, 2, 3, 4, 5, 6, 2, 7]   # target nodes\n",
    "], dtype=torch.long)\n",
    "\n",
    "\n",
    "# Reverse the edges to make the graph undirected\n",
    "edges_reversed = edges_directed[[1, 0], :]\n",
    "\n",
    "# Concatenate the original and reversed edges\n",
    "edges = torch.cat([edges_directed, edges_reversed], dim=1)\n",
    "\n",
    "\n",
    "graphs = []\n",
    "\n",
    "# iterate through each row of data to create a graph for each observation\n",
    "# some nodes will not have any data, not the case here but created a mask to allow us to deal with any nodes that do not have data available\n",
    "for _, row in df_scaled.iterrows():\n",
    "    node_features = []\n",
    "    node_data_mask = []\n",
    "    for node in nodes_order:\n",
    "        if node in df_scaled.columns:\n",
    "            node_features.append([row[node]])\n",
    "            node_data_mask.append(1) # mask value of to indicate present of data\n",
    "        else:\n",
    "            # missing nodes feature if necessary\n",
    "            node_features.append(2)\n",
    "            node_data_mask.append(0) # data not present\n",
    "    \n",
    "    node_features_tensor = torch.tensor(node_features, dtype=torch.float)\n",
    "    node_data_mask_tensor = torch.tensor(node_data_mask, dtype=torch.float)\n",
    "\n",
    "    \n",
    "    # Create a Data object for this row/graph\n",
    "    graph_data = Data(x=node_features_tensor, edge_index=edges.t().contiguous(), mask = node_data_mask_tensor)\n",
    "    graphs.append(graph_data)\n",
    "\n",
    "\n",
    "#### splitting the data into train, test observation\n",
    "# Split indices\n",
    "observation_indices = df_scaled.index.tolist()\n",
    "train_indices, test_indices = train_test_split(observation_indices, test_size=0.05, random_state=42)\n",
    "\n",
    "# Create training and testing graphs\n",
    "train_graphs = [graphs[i] for i in train_indices]\n",
    "test_graphs = [graphs[i] for i in test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert back to NetworkX for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.Graph() \n",
    "for src, dst in edges.t().numpy():\n",
    "    G.add_edge(nodes_order[src], nodes_order[dst])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray', node_size=2000, font_weight='bold')\n",
    "plt.title('Graph Visualization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, num_node_features):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.conv1 = GATConv(num_node_features, 16)\n",
    "        self.conv2 = GATConv(16, 8)\n",
    "        self.fc = nn.Linear(8, 1)  # Outputting a single value per node\n",
    "    \n",
    "        # self.conv1 = GATConv(num_node_features, 16)\n",
    "        # self.conv2 = GATConv(16, 8)\n",
    "        # self.conv3 = GATConv(8, 4)\n",
    "        # self.fc = nn.Linear(4, 1)  # Outputting a single value per node\n",
    "\n",
    "    def forward(self, data, target_node_idx=None):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        edge_index = edge_index.T\n",
    "        x = x.clone()\n",
    "\n",
    "        # Mask the target node's feature with a value of zero! \n",
    "        # Aim is to predict this value from the features of the neighbours\n",
    "        if target_node_idx is not None:\n",
    "            x[target_node_idx] = torch.zeros_like(x[target_node_idx])\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        #x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = GNNModel(num_node_features=1)  \n",
    "batch_size = 8\n",
    "pretrained = True\n",
    "\n",
    "# Load the state dictionary\n",
    "if pretrained:\n",
    "    model_path = \"GNNmodel_state_dict_Batched_new2.pth\"\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-6)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "#criterion = torch.nn.HuberLoss(delta=1.0)  # Huber Loss, delta is the threshold between MAE and MSE\n",
    "\n",
    "num_epochs = 200  # Or any other number of epochs\n",
    "train_loader = DataLoader(train_graphs, batch_size=1, shuffle=True) \n",
    "\n",
    "model.train()\n",
    "\n",
    "actual = []\n",
    "pred = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    accumulated_loss = 0 \n",
    "    optimizer.zero_grad()\n",
    "    loss = 0  # Initialize loss for accumulation\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        mask = data.mask \n",
    "        for i in range(1,data.num_nodes):\n",
    "            if mask[i] == 1 and i != 4:  # Only train on nodes with data\n",
    "                output = model(data, i)  # Get predictions with the target node masked\n",
    "                #print(\"output:\",output)\n",
    "                target = data.x[i] # Ensure target is correctly shaped\n",
    "                prediction = output[i].view(1)  # Ensure prediction is correctly shaped\n",
    "                loss += criterion(prediction, target)\n",
    "                # actual.append(target)\n",
    "                # pred.append(prediction)\n",
    "        #Update parameters at the end of each set of batches\n",
    "        if (batch_idx+1) % batch_size == 0 or (batch_idx +1 ) == len(train_loader):\n",
    "            loss.backward()  # Backpropagate accumulated loss\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            accumulated_loss += loss.item()\n",
    "            loss = 0\n",
    "\n",
    "    average_loss = accumulated_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}, Average Loss: {average_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training\n",
    "model_path = \"GNNmodel_state_dict_Batched_new2.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_graphs, batch_size=1, shuffle=True)\n",
    "\n",
    "#model_path = \"GNNmodel_state_dict_Batched.pth\"\n",
    "#model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "actual = []\n",
    "pred = []\n",
    "\n",
    "for data in test_loader:\n",
    "    mask = data.mask\n",
    "    for i in range(1,4):\n",
    "        if mask[i] == 1:\n",
    "            # if i == 1 or i ==2 or i == 6:\n",
    "            output = model(data, i)\n",
    "            prediction = output[i].view(1)\n",
    "            target = data.x[i]\n",
    "\n",
    "            actual.append(target)\n",
    "            pred.append(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "actual_values_float = [value.item() for value in actual]\n",
    "pred_values_float = [value.item() for value in pred]\n",
    "\n",
    "\n",
    "scatter_trace = go.Scatter(\n",
    "    x=actual_values_float,\n",
    "    y=pred_values_float,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=10,\n",
    "        opacity=0.5,  # Adjust opacity\n",
    "        color='rgba(255,255,255,0)',  # Transparent fill\n",
    "        line=dict(\n",
    "            width=2,\n",
    "            color='rgba(152, 0, 0, .8)',  # Border color\n",
    "        )\n",
    "    ),\n",
    "    name='Actual vs Predicted'\n",
    ")\n",
    "\n",
    "line_trace = go.Scatter(\n",
    "    x=[min(actual_values_float), max(actual_values_float)],\n",
    "    y=[min(actual_values_float), max(actual_values_float)],\n",
    "    mode='lines',\n",
    "    marker=dict(color='blue'),\n",
    "    name='Perfect Prediction'\n",
    ")\n",
    "\n",
    "data = [scatter_trace, line_trace]\n",
    "\n",
    "layout = dict(\n",
    "    title='Actual vs Predicted Values',\n",
    "    xaxis=dict(title='Actual Values'),\n",
    "    yaxis=dict(title='Predicted Values'),\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
